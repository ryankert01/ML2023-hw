{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan\\anaconda3\\envs\\mlhw07\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (AutoTokenizer, AutoModelForQuestionAnswering)\n",
    "from datasets import QA_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import same_seed, read_data\n",
    "\n",
    "device =  'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"./saved_model/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding\n",
    "same_seed(5201314)\n",
    "\n",
    "model_save_dir = \"./saved_model/\" \n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_save_dir).to(device)\n",
    "model_name = \"luhua/chinese_pretrain_mrc_macbert_large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_questions, test_paragraphs = read_data(\"data/hw7_test.json\")\n",
    "test_questions_tokenized = tokenizer([test_question['question_text'] for test_question in test_questions], add_special_tokens=False)\n",
    "test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n",
    "test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_stride = 50\n",
    "\n",
    "def evaluate(data, output, tokenizer, idx):\n",
    "    ##### TODO: Postprocessing #####\n",
    "    # There is a bug and room for improvement in postprocessing \n",
    "    # Hint: Open your prediction file to see what is wrong \n",
    "    \n",
    "    answer = ''\n",
    "    max_prob = float('-inf')\n",
    "    num_of_windows = data[0].shape[1]\n",
    "    \n",
    "    for k in range(num_of_windows):\n",
    "        # Obtain answer by choosing the most probable start position / end position\n",
    "        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n",
    "        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Probability of answer is calculated as sum of start_prob and end_prob\n",
    "        prob = start_prob + end_prob\n",
    "        \n",
    "        # Replace answer if calculated probability is larger than previous windows\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n",
    "            pre_answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n",
    "\n",
    "        # if '[UNK]' in pre_answer:\n",
    "            start_index += doc_stride * k - len(test_questions_tokenized[idx]) - 2\n",
    "            end_index += doc_stride * k - len(test_questions_tokenized[idx]) - 2\n",
    "            if start_index < 0 or end_index < 0:\n",
    "                continue\n",
    "            try:\n",
    "                tokenized_paragraph = test_paragraphs_tokenized[test_questions[idx]['paragraph_id']]\n",
    "                start_index = min(tokenized_paragraph.token_to_chars(start_index))\n",
    "                end_index = max(tokenized_paragraph.token_to_chars(end_index))\n",
    "            except:\n",
    "                print(f\"error! :{start_index}, {end_index}\")\n",
    "                continue\n",
    "            # print(test_paragraphs[test_questions[idx]['paragraph_id']][start_index:end_index])\n",
    "            pre_answer = test_paragraphs[test_questions[idx]['paragraph_id']][start_index:end_index]\n",
    "            if pre_answer != \"\" or len(pre_answer) < 15:\n",
    "                answer = pre_answer\n",
    "    \n",
    "    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n",
    "    answer = answer.replace(' ','')\n",
    "\n",
    "    if answer == \"\":\n",
    "        print(\"empty~ num~ unlls\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 8271, 2399,  ...,    0,    0,    0],\n",
       "         [ 101, 8271, 2399,  ...,    0,    0,    0],\n",
       "         [ 101, 8271, 2399,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 8271, 2399,  ...,    0,    0,    0],\n",
       "         [ 101, 8271, 2399,  ...,    0,    0,    0],\n",
       "         [ 101, 8271, 2399,  ...,    0,    0,    0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年世界盃外圍賽中，韓國打敗兩個國家的代表隊，取得2018年世界盃決賽周參賽資格，其中一個國家是敘利亞，另一個國家是?\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(test_questions[0]['question_text'])\n",
    "print(len(test_questions[0]['question_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [8271, 2399, 686, 4518, 4656, 1912, 1752, 6555, 704, 8024, 7502, 1751, 2802, 3134, 1060, 943, 1751, 2157, 4638, 807, 6134, 7386, 8024, 1357, 2533, 8271, 2399, 686, 4518, 4656, 3748, 6555, 1453, 1347, 6555, 6536, 3419, 8024, 1071, 704, 671, 943, 1751, 2157, 3221, 3135, 1164, 765, 8024, 1369, 671, 943, 1751, 2157, 3221, 136], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token = tokenizer(test_questions[0]['question_text'], add_special_tokens=False)\n",
    "print(token)\n",
    "print(len(token['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014年世界盃外圍賽，韓國在首輪分組賽以首名出線次輪分組賽，與伊朗、卡達、烏茲別克以及黎巴嫩爭逐兩個直接出線決賽周資格，最後韓國僅以較佳的得失球差壓倒烏茲別克，以小組次名取得2014年世界盃決賽周參賽資格，也是韓國連續八次晉身世界盃決賽周。可惜南韓在決賽周表現不濟，三戰一和兩負小組末席出局。2018年世界盃外圍賽，韓國再次在首輪分組賽以首名出線次輪分組賽，再與伊朗、卡達、烏茲別克同組，同組還有中國及敘利亞。最後韓國以兩分壓倒敘利亞及烏茲別克，再以小組次名取得2018年世界盃決賽周參賽資格，也是韓國連續九次晉身世界盃決賽周。韓國的世界盃成績雖然是亞洲最佳，但在亞洲盃足球賽成績就遠不如世界盃。韓國除了在首兩屆亞洲杯奪冠外，但之後一直與亞洲盃錦標無緣，自1992年至2011年更連續六屆未能打入過亞洲盃決賽。2015年亞洲盃足球賽，韓國以五連勝一球不失的姿態，廿七年來首次打入亞洲盃決賽，對手是東道主澳洲。雖然韓國在分組初賽曾以1-0擊敗澳洲，但這場決賽韓國卻先失一球，最後在下半場補時階段扳平，令比賽進入加時階段，可惜澳洲最後在加時階段攻入致勝一球，最後韓國以1-2敗陣，只得亞軍。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paragraphs[test_questions[0]['paragraph_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-11.9815, -11.2627, -15.0886,  ..., -15.2958, -15.2962, -15.2981],\n",
      "        [-12.7801, -13.3592, -14.8644,  ..., -15.3204, -15.3648, -15.3551],\n",
      "        [-12.8654, -13.3881, -15.3689,  ..., -15.4968, -15.5326, -15.5321],\n",
      "        ...,\n",
      "        [-12.4551, -11.5566, -14.5512,  ..., -14.7235, -14.9215, -14.9404],\n",
      "        [-11.8784, -11.2368, -14.3930,  ..., -14.7891, -15.0371, -15.1306],\n",
      "        [-11.7980, -11.9603, -14.4653,  ..., -14.0655, -14.4302, -14.6539]],\n",
      "       device='cuda:0', grad_fn=<CloneBackward0>), end_logits=tensor([[-12.5659, -12.8300, -14.2616,  ..., -14.2505, -14.1121, -14.2462],\n",
      "        [-14.0157, -15.0074, -15.1917,  ..., -15.0789, -15.0030, -14.9334],\n",
      "        [-14.2028, -15.0088, -15.2453,  ..., -15.0352, -14.9889, -14.9522],\n",
      "        ...,\n",
      "        [-12.8251, -14.3696, -14.3306,  ..., -13.3479, -13.1698, -13.1673],\n",
      "        [-12.2557, -14.2416, -14.3133,  ..., -13.0337, -12.8120, -12.6937],\n",
      "        [-11.6966, -14.0086, -14.0644,  ..., -15.1449, -14.8297, -14.6279]],\n",
      "       device='cuda:0', grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "data = test_set[0]\n",
    "output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4166, 5760, 1162, 1046])\n",
      "tensor(131, device='cuda:0')\n",
      "tensor(134, device='cuda:0')\n",
      "58\n",
      "76\n",
      "80\n",
      "烏茲別克，以小組次名取得20\n",
      "烏茲別克\n"
     ]
    }
   ],
   "source": [
    "start_prob, start_index = torch.max(output.start_logits[0], dim=0)\n",
    "end_prob, end_index = torch.max(output.end_logits[0], dim=0)\n",
    "print(data[0][0][start_index : end_index + 1])\n",
    "\n",
    "print(start_index)\n",
    "print(end_index)\n",
    "\n",
    "question_len = len(test_questions_tokenized[0]) + 2\n",
    "print(question_len)\n",
    "start_index -= question_len\n",
    "end_index -= question_len\n",
    "tokenized_paragraph = test_paragraphs_tokenized[test_questions[0]['paragraph_id']]\n",
    "start_index = min(tokenized_paragraph.token_to_chars(start_index))\n",
    "end_index = max(tokenized_paragraph.token_to_chars(end_index))\n",
    "print(start_index)\n",
    "print(end_index)\n",
    "print(test_paragraphs[test_questions[0]['paragraph_id']][start_index:end_index+10])\n",
    "print(test_paragraphs[test_questions[0]['paragraph_id']][start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharSpan(start=76, end=77)\n",
      "CharSpan(start=80, end=81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method UserDict.fromkeys of <class 'transformers.tokenization_utils_base.BatchEncoding'>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_paragraphs_tokenized.token_to_chars(start_index))\n",
    "print(test_paragraphs_tokenized.token_to_chars(end_index))\n",
    "test_paragraphs_tokenized.fromkeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，三戰一'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paragraphs[test_questions[0]['paragraph_id']][133:137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 113/3524 [00:06<02:58, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 206/3524 [00:11<02:47, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 247/3524 [00:13<03:37, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 288/3524 [00:16<03:28, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n",
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 294/3524 [00:16<03:14, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 349/3524 [00:19<02:46, 19.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 361/3524 [00:20<02:37, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :300, 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 399/3524 [00:22<02:47, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 455/3524 [00:25<02:56, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 527/3524 [00:29<02:53, 17.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 553/3524 [00:30<02:39, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 569/3524 [00:31<02:37, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :353, 464\n",
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 578/3524 [00:32<02:40, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 850/3524 [00:47<02:49, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 898/3524 [00:50<02:26, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 913/3524 [00:51<02:26, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 951/3524 [00:53<02:40, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 974/3524 [00:54<02:23, 17.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1020/3524 [00:57<02:09, 19.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1064/3524 [00:59<02:07, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1129/3524 [01:03<01:57, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1184/3524 [01:06<02:11, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :369, 284\n",
      "error! :420, 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1253/3524 [01:10<01:52, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1351/3524 [01:15<01:48, 20.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n",
      "error! :307, 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1360/3524 [01:15<01:40, 21.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1534/3524 [01:25<01:54, 17.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1577/3524 [01:27<01:40, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1589/3524 [01:28<01:51, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1597/3524 [01:28<01:50, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 1633/3524 [01:30<01:49, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1753/3524 [01:37<01:44, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1764/3524 [01:38<01:40, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1779/3524 [01:39<02:01, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1789/3524 [01:39<01:53, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1935/3524 [01:47<01:31, 17.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2021/3524 [01:52<01:25, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2091/3524 [01:56<01:17, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2147/3524 [01:59<01:05, 21.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2178/3524 [02:01<01:10, 19.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2233/3524 [02:04<01:03, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2360/3524 [02:11<01:05, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2438/3524 [02:16<00:53, 20.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 2460/3524 [02:17<00:56, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2609/3524 [02:25<00:49, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 2872/3524 [02:40<00:34, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2935/3524 [02:44<00:29, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :450, 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 2953/3524 [02:45<00:31, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 3148/3524 [02:56<00:22, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :699, 626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3190/3524 [02:58<00:19, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3200/3524 [02:59<00:17, 18.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error! :366, 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 3398/3524 [03:10<00:06, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3426/3524 [03:12<00:05, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty~ num~ unlls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3524/3524 [03:17<00:00, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed! Result is in result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "result = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    idx = 0\n",
    "    for data in tqdm(test_loader):\n",
    "        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "        result.append(evaluate(data, output, tokenizer, idx))\n",
    "        idx += 1\n",
    "\n",
    "result_file = \"result.csv\"\n",
    "with open(result_file, 'w') as f:\t\n",
    "    f.write(\"ID,Answer\\n\")\n",
    "    for i, test_question in enumerate(test_questions):\n",
    "    # Replace commas in answers with empty strings (since csv is separated by comma)\n",
    "    # Answers in kaggle are processed in the same way\n",
    "        f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n",
    "\n",
    "print(f\"Completed! Result is in {result_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhw07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
